{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Wikipedia's Billboard Year-End Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About:\n",
    "\n",
    "This file extracts song information from Wikipedia's pages for Billboard's Year-End Hot 100 charts for years 1960-2020.\n",
    "\n",
    "### Website: \n",
    "\n",
    "https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1960 (*Replace 1960 with any desired year between 1960-2020*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are three years (1963, 1966, 1975) that had an original list, but were revised by Billboard due to errors or recalculations. So the old lists eventually got replaced with a newer list. We will account for these changes and use the revised lists to collect the data in our web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import necessary libraries for scraping websites**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import requests\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia Billboard Year-End pages from 1960-Present follow this format\n",
    "base_url = \"https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_{}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For whatever reason, the HTML formatting used for the 2020 Wikipedia page is a bit different than all the other previous years. We'll just go ahead and begin by web scraping every year besides 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initizialize empty list\n",
    "song_list = []\n",
    "\n",
    "# loop through each year and extract relevant song information to list\n",
    "for year in range(1960,2020):\n",
    "    res = requests.get(base_url.format(year))\n",
    "    soup = bs4.BeautifulSoup(res.text, \"lxml\")\n",
    "    \n",
    "    # break out of loop if website technical issues occur\n",
    "    if res.status_code != 200:\n",
    "        print(\"ERROR. CANNOT SCRAPE ANYMORE.\")\n",
    "        break\n",
    "    \n",
    "    # select revised list if it exists, else get the original list\n",
    "    try:\n",
    "        selection = soup.select('.wikitable')[1]\n",
    "    except:\n",
    "        selection = soup.select('.wikitable')[0]\n",
    "    \n",
    "    tr = selection.select('tr')\n",
    "    \n",
    "    # add each row to song list\n",
    "    for item in tr[1:]:\n",
    "        row_list = []\n",
    "\n",
    "        # append rankings\n",
    "        rank = item.select('td')[0].text\n",
    "        row_list.append(rank)\n",
    "        \n",
    "        # append song titles\n",
    "        title = item.select('td')[1].text\n",
    "        row_list.append(title.strip('\"'))\n",
    "        \n",
    "        # append song artists\n",
    "        artist = item.select('td')[2].text\n",
    "        row_list.append(artist.strip('\\n'))\n",
    "        \n",
    "        # append Billboard year    \n",
    "        row_list.append(year)\n",
    "        \n",
    "        # append row with all of the data above\n",
    "        song_list.append(row_list)\n",
    "        \n",
    "    # slowdown to avoid making quick requests\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's output the first 5 rows and last 5 rows of our list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Theme from A Summer Place', 'Percy Faith', 1960],\n",
       " ['2', \"He'll Have to Go\", 'Jim Reeves', 1960],\n",
       " ['3', \"Cathy's Clown\", 'The Everly Brothers', 1960],\n",
       " ['4', 'Running Bear', 'Johnny Preston', 1960],\n",
       " ['5', 'Teen Angel', 'Mark Dinning', 1960]]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['96', 'Eyes on You', 'Chase Rice', 2019],\n",
       " ['97', 'All to Myself', 'Dan + Shay', 2019],\n",
       " ['98', 'Boyfriend', 'Ariana Grande and Social House', 2019],\n",
       " ['99', 'Walk Me Home', 'Pink', 2019],\n",
       " ['100', 'Robbery', 'Juice Wrld', 2019]]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_list[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like everything is working correctly. We still need song information for the year 2020, so we'll go ahead and do that now using similar code as above, but accounting for the different HTML formatting used in the Wikipedia page for the year 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initizialize empty list\n",
    "song_list_2020 = []\n",
    "\n",
    "# loop through each year and extract relevant song information to list\n",
    "for year in range(2020,2021):\n",
    "    res = requests.get(base_url.format(year))\n",
    "    soup = bs4.BeautifulSoup(res.text, \"lxml\")\n",
    "    \n",
    "    # break out of loop if website technical issues occur\n",
    "    if res.status_code != 200:\n",
    "        print(\"ERROR. CANNOT SCRAPE ANYMORE.\")\n",
    "        break\n",
    "    \n",
    "    # select the original list\n",
    "    selection = soup.select('.wikitable')[0]\n",
    "    \n",
    "    tr = selection.select('tr')\n",
    "    \n",
    "    # add each row to song list\n",
    "    for item in tr[1:]:\n",
    "        row_list = []\n",
    "        \n",
    "        # append rankings\n",
    "        rank = item.select('th')[0].text\n",
    "        row_list.append(rank.strip('\\n'))\n",
    "        \n",
    "        # append song titles\n",
    "        title = item.select('td')[0].text\n",
    "        row_list.append(title.strip('\"'))\n",
    "        \n",
    "        # append song artists\n",
    "        artist = item.select('td')[1].text\n",
    "        row_list.append(artist.strip('\\n'))\n",
    "        \n",
    "        # append Billboard year    \n",
    "        row_list.append(year)\n",
    "        \n",
    "        # append row with all of the data above\n",
    "        song_list_2020.append(row_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, checking the first and last 5 rows of the list, it seems like everything is working as intended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Blinding Lights', 'The Weeknd', 2020],\n",
       " ['2', 'Circles', 'Post Malone', 2020],\n",
       " ['3', 'The Box', 'Roddy Ricch', 2020],\n",
       " ['4', \"Don't Start Now\", 'Dua Lipa', 2020],\n",
       " ['5', 'Rockstar', 'DaBaby featuring Roddy Ricch', 2020]]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_list_2020[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['96', 'More Than My Hometown', 'Morgan Wallen', 2020],\n",
       " ['97', \"Lovin' on You\", 'Luke Combs', 2020],\n",
       " ['98', 'Said Sum', 'Moneybagg Yo', 2020],\n",
       " ['99', 'Slide', 'H.E.R. featuring YG', 2020],\n",
       " ['100', 'Walk Em Down', 'NLE Choppa featuring Roddy Ricch', 2020]]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_list_2020[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our final procedure, we will put everything we gathered together into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('wikipedia_scraper.csv', mode='w', newline='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_writer = csv.writer(file, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write header row\n",
    "csv_writer.writerow(['rank', 'title', 'artist', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_writer.writerows(song_list)\n",
    "csv_writer.writerows(song_list_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
